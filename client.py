import sys
import os
import cv2
import json
import time
import datetime
import numpy as np
import tkinter as tk
from tkinter import messagebox, ttk, filedialog
import traceback
import requests

if sys.platform == "win32":
    try:
        import ctypes
        ctypes.windll.shell32.SetCurrentProcessExplicitAppUserModelID(
            "AISmartMonitor.AISmartMonitor.App"
        )
    except Exception as e:
        print("Kh√¥ng set ƒë∆∞·ª£c AppUserModelID:", e)


SERVER_URL = "https://epd-test.onrender.com/log_incident/"

loading_window = None
progress_bar = None
progress_label = None
root = tk.Tk()
root.withdraw()  

def show_loading_window(title="ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng..."):
    global loading_window, progress_bar, progress_label, root

    loading_window = tk.Toplevel(root)
    loading_window.title(title)
    loading_window.geometry("400x140")
    loading_window.resizable(False, False)
#    loading_window.attributes('-topmost', True)

    tk.Label(loading_window, text="ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng, vui l√≤ng ch·ªù...",
             font=("Arial", 10)).pack(pady=10)

    progress_bar = ttk.Progressbar(loading_window, orient="horizontal", length=350, mode="determinate")
    progress_bar.pack(pady=10)
    progress_bar["maximum"] = 100
    progress_bar["value"] = 0

    progress_label = tk.Label(loading_window, text="0%", font=("Arial", 10, "bold"))
    progress_label.pack()

    # CƒÉn gi·ªØa c·ª≠a s·ªï loading
    root.update_idletasks()
    loading_window.update_idletasks()
    x = root.winfo_x() + (root.winfo_width() - loading_window.winfo_reqwidth()) // 2
    y = root.winfo_y() + (root.winfo_height() - loading_window.winfo_reqheight()) // 2
    loading_window.geometry(f"+{x}+{y}")


def update_progress(percent, text=None):
    if progress_bar and progress_label and loading_window and loading_window.winfo_exists():
        progress_bar["value"] = percent
        if text:
            progress_label.config(text=f"{text} ({percent}%)")
        else:
            progress_label.config(text=f"{percent}%")
        loading_window.update_idletasks()

def destroy_loading_window():
    global loading_window
    if loading_window and loading_window.winfo_exists():
        loading_window.destroy()

show_loading_window("ƒêang kh·ªüi ƒë·ªông ch∆∞∆°ng tr√¨nh...")

update_progress(50, "ƒêang kh·ªüi ƒë·ªông m√¥ h√¨nh mediapipe")
import mediapipe as mp
update_progress(70, "ƒêang kh·ªüi ƒë·ªông giao di·ªán")
from PyQt6.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                             QHBoxLayout, QPushButton, QLabel, QComboBox, 
                             QFrame, QSplitter, QMessageBox, QInputDialog, 
                             QFileDialog, QScrollArea, QGridLayout,QMenu)
from PyQt6.QtCore import Qt, QThread, pyqtSignal
from PyQt6.QtGui import QImage, QPixmap, QFont, QIcon
from PyQt6.QtMultimedia import QMediaDevices

update_progress(100, "Ho√†n t·∫•t")
destroy_loading_window()

def send_to_server(data, class_name, mode):
    try:
        now = datetime.datetime.now()
        end_str = now.strftime('%H:%M:%S')
        date_str = now.strftime('%Y-%m-%d') # <--- [M·ªöI] L·∫•y ng√†y hi·ªán t·∫°i (NƒÉm-Th√°ng-Ng√†y)

        payload = {
            "class_id": class_name,
            "zone_id": str(data['student_id']),
            "issue_type": data['behavior'],
            "start_time": data['timestamp'],
            "end_time": end_str,
            "duration_seconds": data['duration'],
            "date": date_str, # <--- [M·ªöI] G·ª≠i th√™m ng√†y
            "scan_mode": mode
        }
        
        # G·ª≠i ƒëi
        requests.post(SERVER_URL, json=payload, timeout=2)
        print(f"‚úÖ ƒê√£ g·ª≠i l√™n Web (Mode: {mode}) - ({date_str}): HS-{data['student_id']} - {data['behavior']}")
    except requests.exceptions.Timeout:
        print("‚ùå G·ª≠i l√™n web b·ªã Timeout (Qu√° 2 gi√¢y).")
    except Exception as e:
        print(f"‚ùå L·ªói khi g·ª≠i d·ªØ li·ªáu l√™n Web: {e}")

class BehaviorTracker:
    def __init__(self, threshold_seconds=5):
        self.threshold = threshold_seconds
        self.tracking_data = {} 
        
    def update(self, student_id, current_status):
        now = time.time()
        
        # N·∫øu h·ªçc sinh n√†y ch∆∞a t·ª´ng b·ªã theo d√µi
        if student_id not in self.tracking_data:
            # Ch·ªâ b·∫Øt ƒë·∫ßu theo d√µi n·∫øu h√†nh vi l√† X·∫§U
            if self.is_bad_behavior(current_status):
                self.tracking_data[student_id] = {'status': current_status, 'start_time': now}
            return None

        # N·∫øu ƒëang theo d√µi
        data = self.tracking_data[student_id]
        
        # N·∫øu tr·∫°ng th√°i thay ƒë·ªïi (ƒëang Ng·ªß -> T·ªânh, ho·∫∑c Ng·ªß -> M·∫•t t·∫≠p trung)
        if current_status != data['status']:
            duration = now - data['start_time']
            last_status = data['status']
            start_ts = data['start_time']
            
            # X√≥a tr·∫°ng th√°i c≈© ƒëi
            del self.tracking_data[student_id]
            
            # N·∫øu h√†nh vi m·ªõi c≈©ng x·∫•u -> B·∫Øt ƒë·∫ßu theo d√µi c√°i m·ªõi ngay
            if self.is_bad_behavior(current_status):
                self.tracking_data[student_id] = {'status': current_status, 'start_time': now}

            # QUAN TR·ªåNG: Ki·ªÉm tra xem h√†nh vi c≈© ƒë√£ k√©o d√†i ƒë·ªß l√¢u ch∆∞a ƒë·ªÉ b√°o c√°o
            if duration >= self.threshold:
                return self.create_report(student_id, last_status, duration, start_ts)
                
        return None

    def is_bad_behavior(self, status):
        # C·∫≠p nh·∫≠t t·ª´ kh√≥a kh·ªõp v·ªõi AIProcessor
        bad_keywords = ["Bu·ªìn ng·ªß", "M·∫•t t·∫≠p trung", "CƒÉng th·∫≥ng", "Bu·ªìn", "M·ªát m·ªèi", "Thu m√¨nh"]
        return any(keyword in status for keyword in bad_keywords)

    def create_report(self, student_id, status, duration, start_timestamp):
        return {
            "student_id": student_id,
            "behavior": status,
            "duration": round(duration, 1),
            "timestamp": datetime.datetime.fromtimestamp(start_timestamp).strftime('%H:%M:%S')
        }
    
    # --- H√ÄM M·ªöI: CH·ªêT S·ªî KHI T·∫ÆT APP ---
    def finalize_all(self):
        """Tr·∫£ v·ªÅ danh s√°ch t·∫•t c·∫£ c√°c h√†nh vi ƒëang di·ªÖn ra ch∆∞a k·∫øt th√∫c"""
        reports = []
        now = time.time()
        for sid, data in self.tracking_data.items():
            duration = now - data['start_time']
            if duration >= self.threshold:
                reports.append(self.create_report(sid, data['status'], duration, data['start_time']))
        self.tracking_data.clear()
        return reports

# ======================================================
# 1. AI PROCESSOR (N√ÇNG C·∫§P CHO CH·ª¶ ƒê·ªÄ T√ÇM L√ù)
# ======================================================
class AIProcessor:
    def __init__(self):
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

    # --- H√ÄM T√çNH TO√ÅN C≈® (GI·ªÆ NGUY√äN) ---
    def calculate_ear(self, landmarks, indices):
        try:
            p1 = np.array([landmarks[indices[0]].x, landmarks[indices[0]].y])
            p2 = np.array([landmarks[indices[1]].x, landmarks[indices[1]].y])
            p3 = np.array([landmarks[indices[2]].x, landmarks[indices[2]].y])
            p4 = np.array([landmarks[indices[3]].x, landmarks[indices[3]].y])
            p5 = np.array([landmarks[indices[4]].x, landmarks[indices[4]].y])
            p6 = np.array([landmarks[indices[5]].x, landmarks[indices[5]].y])
            vertical = np.linalg.norm(p2 - p6) + np.linalg.norm(p3 - p5)
            horizontal = np.linalg.norm(p1 - p4) * 2.0
            return vertical / horizontal
        except: return 0.0

    def calculate_mar(self, landmarks):
        try:
            top = np.array([landmarks[13].x, landmarks[13].y])
            bottom = np.array([landmarks[14].x, landmarks[14].y])
            left = np.array([landmarks[61].x, landmarks[61].y])
            right = np.array([landmarks[291].x, landmarks[291].y])
            return np.linalg.norm(top - bottom) / np.linalg.norm(left - right)
        except: return 0.0

    def get_head_pose(self, landmarks):
        try:
            nose = landmarks[1].x
            left_ear = landmarks[234].x
            right_ear = landmarks[454].x
            ratio = (nose - left_ear) / (right_ear - nose + 0.0001)

            if ratio < 0.5: return "N√© tr√°nh (Tr√°i)" # ƒê·ªïi t√™n cho h·ª£p t√¢m l√Ω
            if ratio > 2.0: return "N√© tr√°nh (Ph·∫£i)"
            
            if (landmarks[1].y - landmarks[10].y) < 0.03: 
                return "C√∫i ƒë·∫ßu"
            return "Th·∫≥ng"
        except: return "Kƒê"

    # --- H√ÄM M·ªöI: PH√ÅT HI·ªÜN C·∫¢M X√öC (LOGIC H√åNH H·ªåC) ---
    def detect_emotion(self, landmarks):
        try:
            # 1. L·∫•y t·ªça ƒë·ªô
            # Kh√≥e mi·ªáng tr√°i (61) v√† ph·∫£i (291)
            mouth_corner_y = (landmarks[61].y + landmarks[291].y) / 2
            
            # Trung t√¢m m√¥i (l·∫•y ƒëi·ªÉm gi·ªØa m√¥i tr√™n 13 v√† m√¥i d∆∞·ªõi 14)
            mouth_center_y = (landmarks[13].y + landmarks[14].y) / 2
            
            # M√¥i tr√™n (0) d√πng ƒë·ªÉ check n·ª• c∆∞·ªùi
            upper_lip_y = landmarks[0].y
            
            # L√¥ng m√†y ƒë·ªÉ check stress
            brow_left = np.array([landmarks[107].x, landmarks[107].y])
            brow_right = np.array([landmarks[336].x, landmarks[336].y])
            face_width = np.linalg.norm(np.array([landmarks[234].x, landmarks[234].y]) - 
                                        np.array([landmarks[454].x, landmarks[454].y]))
            brow_dist = np.linalg.norm(brow_left - brow_right)
            brow_ratio = brow_dist / face_width

            # 2. Logic ph√°n ƒëo√°n
            # L∆∞u √Ω: Trong ·∫£nh m√°y t√≠nh, tr·ª•c Y c√†ng l·ªõn th√¨ c√†ng n·∫±m th·∫•p b√™n d∆∞·ªõi
            
            # N·∫øu kh√≥e mi·ªáng CAO H∆†N m√¥i tr√™n -> C∆∞·ªùi
            if mouth_corner_y < upper_lip_y: 
                return "T√≠ch c·ª±c/Vui v·∫ª üòä"
            
            # [M·ªöI] N·∫øu kh√≥e mi·ªáng TH·∫§P H∆†N trung t√¢m m√¥i m·ªôt kho·∫£ng -> Bu·ªìn
            # 0.02 l√† ng∆∞·ª°ng (threshold), b·∫°n c√≥ th·ªÉ ch·ªânh s·ªë n√†y n·∫øu th·∫•y ch∆∞a nh·∫°y
            elif mouth_corner_y > mouth_center_y + 0.0025:
                return "Bu·ªìn / Ch√°n n·∫£n üòû"
            
            # N·∫øu l√¥ng m√†y qu√° g·∫ßn nhau -> Stress
            elif brow_ratio < 0.16: 
                return "CƒÉng th·∫≥ng/Stress üòñ"
                
            else:
                return "B√¨nh th∆∞·ªùng"
        except:
            return "B√¨nh th∆∞·ªùng"
    def process_zone(self, frame_crop):
        if frame_crop is None or frame_crop.shape[0] == 0 or frame_crop.shape[1] == 0:
            return "NO DATA", (100, 100, 100)

        rgb_crop = cv2.cvtColor(frame_crop, cv2.COLOR_BGR2RGB)
        rgb_crop.flags.writeable = False
        results = self.face_mesh.process(rgb_crop)
        rgb_crop.flags.writeable = True

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0].landmark
            
            # T√≠nh to√°n c√°c ch·ªâ s·ªë
            LEFT_EYE = [33, 160, 158, 133, 153, 144]
            RIGHT_EYE = [362, 385, 387, 263, 373, 380]
            ear = (self.calculate_ear(landmarks, LEFT_EYE) + self.calculate_ear(landmarks, RIGHT_EYE)) / 2.0
            mar = self.calculate_mar(landmarks)
            pose = self.get_head_pose(landmarks)
            emotion = self.detect_emotion(landmarks)

            # --- LOGIC CH·∫®N ƒêO√ÅN T√ÇM L√ù (QUAN TR·ªåNG) ---
            status = "·ªîn ƒë·ªãnh"
            color = (0, 255, 0) # Xanh l√°

            # ∆Øu ti√™n 1: C√°c d·∫•u hi·ªáu s·ª©c kh·ªèe th·ªÉ ch·∫•t (M·ªát m·ªèi)
            if ear < 0.20:
                status = "Ki·ªát s·ª©c / Bu·ªìn ng·ªß üò¥"
                color = (0, 0, 255) # ƒê·ªè
            elif mar > 0.5:
                status = "M·ªát m·ªèi / Thi·∫øu oxy ü•±"
                color = (0, 165, 255) # Cam
            
            # ∆Øu ti√™n 2: H√†nh vi/T∆∞ th·∫ø (Thu m√¨nh)
            elif pose == "C√∫i ƒë·∫ßu":
                 status = "Thu m√¨nh / Tr·∫ßm t∆∞ üôá"
                 color = (255, 0, 255) # T√≠m
            elif "N√© tr√°nh" in pose:
                status = f"M·∫•t t·∫≠p trung ({pose})"
                color = (0, 255, 255) # V√†ng

            # ∆Øu ti√™n 3: C·∫£m x√∫c (N·∫øu t∆∞ th·∫ø v√† m·∫Øt b√¨nh th∆∞·ªùng)
            elif "CƒÉng th·∫≥ng" in emotion:
                status = "CƒÉng th·∫≥ng / Lo √¢u üòñ"
                color = (128, 0, 128) # T√≠m ƒë·∫≠m
            
            # [TH√äM M·ªöI] X·ª≠ l√Ω tr·∫°ng th√°i Bu·ªìn
            elif "Bu·ªìn" in emotion:
                status = "Bu·ªìn / Ch√°n n·∫£n üòû"
                color = (0, 100, 255) # Xanh d∆∞∆°ng ƒë·∫≠m (M√†u ƒë·∫∑c tr∆∞ng c·ªßa n·ªói bu·ªìn)

            elif "T√≠ch c·ª±c" in emotion:
                status = "T√≠ch c·ª±c / H·ª©ng th√∫ üòÑ"
                color = (0, 255, 127) # Xanh l∆°

            return status, color
        else:
            return "V·∫Øng / K.Th·∫•y M·∫∑t", (128, 128, 128)
# ======================================================
# 2. THREAD VIDEO (ƒê√É C·∫¨P NH·∫¨T T·ªêI ∆ØU & TRACKER)
# ======================================================
class VideoThread(QThread):
    change_pixmap_signal = pyqtSignal(QImage)
    update_board_signal = pyqtSignal(list)
    error_signal = pyqtSignal(str)
    
    def __init__(self, camera_index=0):
        super().__init__()
        self.camera_index = camera_index
        self._is_running = True
        self.is_monitoring = False
        
        self.ai = AIProcessor()
        
        # --- [TH√äM M·ªöI] KH·ªûI T·∫†O B·ªò THEO D√ïI H√ÄNH VI ---
        # threshold_seconds=5: Ph·∫£i duy tr√¨ tr·∫°ng th√°i x·∫•u 5 gi√¢y m·ªõi b√°o c√°o
        self.tracker = BehaviorTracker(threshold_seconds=5) 
        
        self.video_width = 640
        self.video_height = 480
        self.zones = [] 
        self.current_drawing_zone = None
        self.frame_count = 0 
        self.last_statuses = {} 

        # C·∫•u h√¨nh t·ªëi ∆∞u: 30 frame m·ªõi ch·∫°y AI 1 l·∫ßn (t∆∞∆°ng ƒë∆∞∆°ng 1 gi√¢y)
        self.SKIP_FRAMES = 30 

    def run(self):
        if sys.platform == 'win32':
            cap = cv2.VideoCapture(self.camera_index, cv2.CAP_DSHOW)
        else:
            cap = cv2.VideoCapture(self.camera_index)
            
        try:
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        except:
            pass

        if not cap.isOpened():
            self.error_signal.emit("Kh√¥ng th·ªÉ m·ªü Camera!")
            return

        while self._is_running:
            try:
                ret, cv_img = cap.read()
                if not ret:
                    continue
                
                self.video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                self.video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                self.frame_count += 1
                
                if self.is_monitoring:
                    final_results = []
                    
                    # --- [T·ªêI ∆ØU] Ch·ªâ ch·∫°y AI m·ªói 30 frame (1 gi√¢y/l·∫ßn) ---
                    should_process_ai = (self.frame_count % self.SKIP_FRAMES == 0)

                    for zone in self.zones:
                        z_id = str(zone["id"]) # ƒê·∫£m b·∫£o ID l√† string ƒë·ªÉ kh·ªõp v·ªõi Tracker
                        
                        # 1. GIAI ƒêO·∫†N X·ª¨ L√ù AI (N·∫∂NG - CH·∫†Y √çT)
                        if should_process_ai:
                            x, y, w, h = zone["rect"]
                            x = max(0, x); y = max(0, y)
                            w = min(w, self.video_width - x); h = min(h, self.video_height - y)
                            
                            if w > 0 and h > 0:
                                roi = cv_img[y:y+h, x:x+w]
                                status, color = self.ai.process_zone(roi)
                                
                                # L∆∞u v√†o Cache ƒë·ªÉ v·∫Ω li√™n t·ª•c
                                self.last_statuses[z_id] = {"status": status, "color": color}
                                
                                # --- [TH√äM M·ªöI] G·ªåI TRACKER ƒê·ªÇ KI·ªÇM TRA TH·ªúI GIAN ---
                                report = self.tracker.update(z_id, status)
                                if report:
                                    # G·ª≠i l√™n server ngay l·∫≠p t·ª©c (Th√™m self.current_class v√†o)
                                    send_to_server(report, self.current_class, "epd_distraction")      
                        
                        # 2. GIAI ƒêO·∫†N V·∫º (NH·∫∏ - CH·∫†Y LI√äN T·ª§C)
                        # L·∫•y d·ªØ li·ªáu t·ª´ cache ra v·∫Ω
                        cached = self.last_statuses.get(z_id, {"status": "ƒêang t·∫£i...", "color": (200,200,200)})
                        
                        # Th√™m v√†o danh s√°ch ƒë·ªÉ c·∫≠p nh·∫≠t b·∫£ng b√™n ph·∫£i
                        final_results.append({"id": z_id, "status": cached["status"], "color": cached["color"]})
                        
                        # V·∫Ω khung h√¨nh ch·ªØ nh·∫≠t tr√™n video
                        cv2.rectangle(cv_img, (zone["rect"][0], zone["rect"][1]), 
                                      (zone["rect"][0]+zone["rect"][2], zone["rect"][1]+zone["rect"][3]), 
                                      cached["color"], 2)
                        # V·∫Ω ID nh·ªè tr√™n ƒë·∫ßu khung
                        cv2.putText(cv_img, f"HS-{z_id}", (zone["rect"][0], zone["rect"][1]-5),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, cached["color"], 1)
                    
                    self.update_board_signal.emit(final_results)
                else:
                    # --- CH·∫æ ƒê·ªò CH·ªú (V·∫º KHUNG V√ÄNG & ID R√ï N√âT) ---
                    for zone in self.zones:
                         x, y, w, h = zone["rect"]
                         z_id = str(zone['id'])
                         
                         # 1. V·∫Ω khung v√†ng
                         cv2.rectangle(cv_img, (x, y), (x+w, y+h), (0, 255, 255), 2)
                         
                         # 2. V·∫Ω n·ªÅn ƒëen cho ch·ªØ (ƒë·ªÉ d·ªÖ ƒë·ªçc)
                         label = f"HS-{z_id}"
                         (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)
                         cv2.rectangle(cv_img, (x, y - 20), (x + tw + 10, y), (0, 255, 255), -1) # N·ªÅn v√†ng
                         
                         # 3. V·∫Ω ch·ªØ ƒëen l√™n n·ªÅn v√†ng
                         cv2.putText(cv_img, label, (x + 5, y - 5), 
                                     cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

                    # V·∫Ω v√πng ƒëang k√©o chu·ªôt (n·∫øu c√≥)
                    if self.current_drawing_zone:
                        dx, dy, dw, dh = self.current_drawing_zone
                        cv2.rectangle(cv_img, (dx, dy), (dx+dw, dy+dh), (0, 165, 255), 2)

                # Chuy·ªÉn ƒë·ªïi ·∫£nh sang Qt
                rgb_image = cv2.cvtColor(cv_img, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb_image.shape
                bytes_per_line = ch * w
                qt_image = QImage(rgb_image.data, w, h, bytes_per_line, QImage.Format.Format_RGB888)
                self.change_pixmap_signal.emit(qt_image.copy())

            except Exception as e:
                print(f"Error in thread: {e}")
                traceback.print_exc()

        cap.release()

    def stop(self):
        self._is_running = False
        if self.is_monitoring:
            print("ƒêang t·ªïng k·∫øt d·ªØ li·ªáu...")
            final_reports = self.tracker.finalize_all()
            for rep in final_reports:
                # TRUY·ªÄN TH√äM T√äN L·ªöP KHI T·∫ÆT
                send_to_server(rep, self.current_class, "epd_distraction") 
        self.wait()
# ======================================================
# 3. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (GI·ªÆ NGUY√äN)
# ======================================================
class CameraMonitorUI(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("H·ªá Th·ªëng Gi√°m S√°t L·ªõp H·ªçc - AI Smart Monitor")
        self.resize(1400, 850)
        self.thread = None
        self.is_drawing_mode = False
        self.start_point = None
        self.current_temp_zone = None 
        self.student_widgets = {} 
        self.is_monitoring_active = False 
        self.current_pixmap = None

        self.setup_ui()
        self.apply_styles()
        self.load_available_cameras()

    def resizeEvent(self, event):
        super().resizeEvent(event)
        self.refresh_video_view()

    def refresh_video_view(self):
        if self.current_pixmap is None:
            return
        
        scaled = self.current_pixmap.scaled(
            self.video_label.size(),
            Qt.AspectRatioMode.KeepAspectRatio,   # üî• GI·ªÆ T·ªà L·ªÜ
            Qt.TransformationMode.SmoothTransformation
        )
        self.video_label.setPixmap(scaled)

    def update_video_frame(self, image: QImage):
        pixmap = QPixmap.fromImage(image)
        self.current_pixmap = pixmap
        self.refresh_video_view()

    def setup_ui(self):
        self.setFont(QFont("Segoe UI", 10))
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)
        splitter = QSplitter(Qt.Orientation.Horizontal)

        self.video_container = QWidget()
        v_layout = QVBoxLayout(self.video_container)
        v_layout.setContentsMargins(0,0,0,0)
        self.video_label = QLabel("Vui l√≤ng ch·ªçn Camera...")
        self.video_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.video_label.setScaledContents(False) 
        self.video_label.setMouseTracking(True) 
        self.video_label.mousePressEvent = self.on_mouse_press
        self.video_label.mouseMoveEvent = self.on_mouse_move
        self.video_label.mouseReleaseEvent = self.on_mouse_release
        v_layout.addWidget(self.video_label)

        sidebar = QFrame()
        sidebar.setFixedWidth(450)
        sb_layout = QVBoxLayout(sidebar)
        
        self.grp_setup = QFrame()
        setup_layout = QVBoxLayout(self.grp_setup)
        self.combo_cam = QComboBox()
        self.combo_cam.currentIndexChanged.connect(self.start_camera_stream)
        setup_layout.addWidget(QLabel("Ngu·ªìn Camera:"))
        setup_layout.addWidget(self.combo_cam)
        setup_layout.addWidget(QLabel("üè´ Ch·ªçn L·ªõp H·ªçc:"))
        self.combo_class_select = QComboBox()
        # Danh s√°ch c√°c l·ªõp (b·∫°n c√≥ th·ªÉ s·ª≠a t√πy √Ω)
        self.combo_class_select.addItems(["L·ªõp 12A1", "L·ªõp 12A2", "L·ªõp 12A3", "L·ªõp 12A4", "L·ªõp 12A5"])
        self.combo_class_select.currentTextChanged.connect(self.update_class_name)
        setup_layout.addWidget(self.combo_class_select)
        self.btn_draw = QPushButton("üñå TH√äM V·ªä TR√ç H·ªåC SINH")
        self.btn_draw.setCheckable(True)
        self.btn_draw.clicked.connect(self.toggle_drawing_mode)
        setup_layout.addWidget(self.btn_draw)
        
        self.btn_confirm_zone = QPushButton("‚úÖ X√ÅC NH·∫¨N V√ôNG")
        self.btn_confirm_zone.clicked.connect(self.confirm_current_zone)
        self.btn_confirm_zone.setEnabled(False)
        setup_layout.addWidget(self.btn_confirm_zone)
        
        h_file = QHBoxLayout()
        btn_save = QPushButton("üíæ L∆∞u C·∫•u H√¨nh"); btn_save.clicked.connect(self.save_layout_to_file)
        btn_load = QPushButton("üìÇ M·ªü C·∫•u H√¨nh"); btn_load.clicked.connect(self.load_layout_from_file)
        h_file.addWidget(btn_save); h_file.addWidget(btn_load)
        setup_layout.addLayout(h_file)
        
        sb_layout.addWidget(self.grp_setup)
        
        self.btn_start_monitor = QPushButton("‚ñ∂ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH AI")
        self.btn_start_monitor.setMinimumHeight(60)
        self.btn_start_monitor.setStyleSheet("background-color: #2e7d32; font-size: 16px; font-weight: bold;")
        self.btn_start_monitor.clicked.connect(self.toggle_monitoring)
        sb_layout.addWidget(self.btn_start_monitor)
        
        sb_layout.addWidget(self.create_line())
        sb_layout.addWidget(QLabel("üìä TR·∫†NG TH√ÅI H·ªåC SINH (Grid View)"))
        
        self.scroll_area = QScrollArea()
        self.scroll_area.setWidgetResizable(True)
        self.scroll_content = QWidget()
        self.grid_layout = QGridLayout(self.scroll_content)
        self.grid_layout.setAlignment(Qt.AlignmentFlag.AlignTop)
        self.scroll_area.setWidget(self.scroll_content)
        sb_layout.addWidget(self.scroll_area)

        splitter.addWidget(self.video_container)
        splitter.addWidget(sidebar)
        splitter.setSizes([950, 450])
        main_layout.addWidget(splitter)

    def update_class_name(self, text):
        if self.thread:
            self.thread.current_class = text
            print(f"ƒê√£ ƒë·ªïi sang l·ªõp: {text}")
    
    def handle_thread_error(self, err_msg):
        QMessageBox.critical(self, "L·ªói", err_msg)
        self.combo_cam.setCurrentIndex(-1)

    def start_camera_stream(self):
        idx = self.combo_cam.currentIndex()
        if idx < 0: return
        if self.thread: self.thread.stop()
        
        self.thread = VideoThread(camera_index=idx)
        # C·∫≠p nh·∫≠t t√™n l·ªõp ngay khi kh·ªüi t·∫°o
        self.thread.current_class = self.combo_class_select.currentText() 
        
        self.thread.change_pixmap_signal.connect(self.update_video_frame)
        self.thread.update_board_signal.connect(self.update_student_panel)
        self.thread.error_signal.connect(self.handle_thread_error)
        self.thread.start()

    def toggle_monitoring(self):
        if not self.thread: return
        self.is_monitoring_active = not self.is_monitoring_active
        if self.is_monitoring_active:
            self.thread.is_monitoring = True
            self.btn_start_monitor.setText("‚èπ D·ª™NG PH√ÇN T√çCH")
            self.btn_start_monitor.setStyleSheet("background-color: #c62828; font-size: 16px; font-weight: bold;")
            self.grp_setup.setEnabled(False)
            self.is_drawing_mode = False; self.btn_draw.setChecked(False)
        else:
            self.thread.is_monitoring = False
            self.btn_start_monitor.setText("‚ñ∂ B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH AI")
            self.btn_start_monitor.setStyleSheet("background-color: #2e7d32; font-size: 16px; font-weight: bold;")
            self.grp_setup.setEnabled(True)
            for w in self.student_widgets.values():
                w.lbl_stat.setText("Ch·ªù..."); w.setStyleSheet("background-color: #424242; border-radius: 4px;")

    def update_student_panel(self, data_list):
        COLUMNS = 3
        # X√≥a c√°c widget c·ªßa v√πng ƒë√£ b·ªã x√≥a kh·ªèi d·ªØ li·ªáu nh∆∞ng v·∫´n c√≤n tr√™n giao di·ªán
        active_ids = [item['id'] for item in data_list]
        for sid in list(self.student_widgets.keys()):
            if sid not in active_ids:
                self.student_widgets[sid].setParent(None)
                del self.student_widgets[sid]

        for index, item in enumerate(data_list):
            sid = item['id']
            status_text = item['status']
            
            if sid not in self.student_widgets:
                card = QFrame()
                card.setFixedSize(130, 80) 
                l = QVBoxLayout(card); l.setContentsMargins(2,2,2,2); l.setSpacing(0)
                
                lbl_id = QLabel(f"HS {sid}"); lbl_id.setAlignment(Qt.AlignmentFlag.AlignCenter)
                lbl_id.setStyleSheet("font-weight: bold; color: white;")
                
                lbl_stat = QLabel(status_text); lbl_stat.setAlignment(Qt.AlignmentFlag.AlignCenter)
                lbl_stat.setWordWrap(True) 
                lbl_stat.setStyleSheet("font-size: 11px; color: white;")
                
                card.lbl_stat = lbl_stat
                l.addWidget(lbl_id); l.addWidget(lbl_stat)
                
                # --- [M·ªöI] C·∫§U H√åNH MENU CHU·ªòT PH·∫¢I ---
                card.setContextMenuPolicy(Qt.ContextMenuPolicy.CustomContextMenu)
                # D√πng lambda ƒë·ªÉ truy·ªÅn ƒë√∫ng ID c·ªßa h·ªçc sinh c·∫ßn x√≥a
                card.customContextMenuRequested.connect(lambda pos, s=sid: self.show_context_menu(pos, s))
                # -------------------------------------

                self.grid_layout.addWidget(card, index // COLUMNS, index % COLUMNS)
                self.student_widgets[sid] = card
            
            # ... (Ph·∫ßn c·∫≠p nh·∫≠t m√†u s·∫Øc b√™n d∆∞·ªõi gi·ªØ nguy√™n) ...
            w = self.student_widgets[sid]
            w.lbl_stat.setText(status_text)
            
            bg_color = "#2e7d32" 
            if "NG·ª¶" in status_text: bg_color = "#d32f2f" 
            elif "V·∫Øng" in status_text: bg_color = "#424242" 
            elif "NG√ÅP" in status_text: bg_color = "#ef6c00" 
            elif "M·∫•t t·∫≠p trung" in status_text: bg_color = "#f9a825" 
            elif "C√∫i" in status_text: bg_color = "#7b1fa2" 
            
            w.setStyleSheet(f"background-color: {bg_color}; border-radius: 6px;")

    def save_layout_to_file(self):
        if not self.thread or not self.thread.zones: return
        name, ok = QInputDialog.getText(self, "L∆∞u", "Nh·∫≠p t√™n file (kh√¥ng d·∫•u):")
        if ok and name:
            with open(f"{name}.json", 'w') as f: json.dump(self.thread.zones, f)
            QMessageBox.information(self, "Th√†nh c√¥ng", "ƒê√£ l∆∞u b·∫£n ƒë·ªì l·ªõp h·ªçc.")

    def load_layout_from_file(self):
        fname, _ = QFileDialog.getOpenFileName(self, "M·ªü", "", "JSON (*.json)")
        if not fname or not self.thread: return
        try:
            with open(fname, 'r') as f: 
                self.thread.zones = json.load(f)
                for i in reversed(range(self.grid_layout.count())): 
                    self.grid_layout.itemAt(i).widget().setParent(None)
                self.student_widgets.clear()
                QMessageBox.information(self, "Th√†nh c√¥ng", f"ƒê√£ n·∫°p {len(self.thread.zones)} v·ªã tr√≠ h·ªçc sinh.")
        except Exception as e: QMessageBox.warning(self, "L·ªói", str(e))

    def toggle_drawing_mode(self):
        self.is_drawing_mode = self.btn_draw.isChecked()
        self.btn_draw.setText("‚ùå H·ª¶Y V·∫º" if self.is_drawing_mode else "üñå TH√äM V·ªä TR√ç H·ªåC SINH")
        self.btn_draw.setStyleSheet("background-color: #d32f2f;" if self.is_drawing_mode else "")

    def confirm_current_zone(self):
            if self.current_temp_zone and self.thread:
                # --- [S·ª¨A ƒê·ªîI] LOGIC SINH ID TH√îNG MINH ---
                # T√¨m ID l·ªõn nh·∫•t hi·ªán c√≥ ƒë·ªÉ c·ªông th√™m 1, tr√°nh b·ªã tr√πng khi ƒë√£ x√≥a b·ªõt
                existing_ids = [int(z['id']) for z in self.thread.zones]
                if existing_ids:
                    new_id = max(existing_ids) + 1
                else:
                    new_id = 1
                # ------------------------------------------

                self.thread.zones.append({"id": new_id, "rect": self.current_temp_zone})
                self.thread.current_drawing_zone = None
                self.current_temp_zone = None
                self.btn_confirm_zone.setEnabled(False)
                print(f"‚úÖ ƒê√£ th√™m v√πng m·ªõi: HS-{new_id}")
    def get_real_coords(self, qpoint):
        if not self.thread or self.current_pixmap is None:
            return 0, 0

        lbl_w = self.video_label.width()
        lbl_h = self.video_label.height()

        vid_w = self.thread.video_width
        vid_h = self.thread.video_height

        if lbl_w == 0 or lbl_h == 0:
            return 0, 0

        # üî• T√≠nh t·ªâ l·ªá scale GI·ªÆ NGUY√äN T·ªà L·ªÜ
        scale = min(lbl_w / vid_w, lbl_h / vid_h)

        # üî• K√≠ch th∆∞·ªõc video sau khi scale
        disp_w = vid_w * scale
        disp_h = vid_h * scale

        # üî• Ph·∫ßn vi·ªÅn ƒëen
        offset_x = (lbl_w - disp_w) / 2
        offset_y = (lbl_h - disp_h) / 2

        # üî• T·ªça ƒë·ªô chu·ªôt t∆∞∆°ng ƒë·ªëi so v·ªõi video
        x = qpoint.x() - offset_x
        y = qpoint.y() - offset_y

        # N·∫øu click v√†o v√πng vi·ªÅn ƒëen ‚Üí b·ªè
        if x < 0 or y < 0 or x > disp_w or y > disp_h:
            return None, None

        # üî• Quy ƒë·ªïi v·ªÅ t·ªça ƒë·ªô frame g·ªëc
        real_x = int(x / scale)
        real_y = int(y / scale)

        return real_x, real_y

    def on_mouse_press(self, event):
        if self.is_drawing_mode and event.button() == Qt.MouseButton.LeftButton:
            pt = self.get_real_coords(event.position())
            if pt[0] is None:
                return
            self.start_point = pt


    def on_mouse_move(self, event):
        if self.is_drawing_mode and self.start_point:
            cur = self.get_real_coords(event.position())
            if cur[0] is None:
                return

            x1, y1 = self.start_point
            x2, y2 = cur

            self.thread.current_drawing_zone = (
                min(x1, x2),
                min(y1, y2),
                abs(x2 - x1),
                abs(y2 - y1)
            )

    def on_mouse_release(self, event):
        if self.is_drawing_mode:
            if self.thread.current_drawing_zone and self.thread.current_drawing_zone[2] > 10:
                self.current_temp_zone = self.thread.current_drawing_zone
                self.btn_confirm_zone.setEnabled(True)

            self.start_point = None


    def load_available_cameras(self):
        self.combo_cam.clear()
        for i in range(len(QMediaDevices.videoInputs())): self.combo_cam.addItem(f"Camera {i}")

    def create_line(self):
        l = QFrame(); l.setFrameShape(QFrame.Shape.HLine); l.setStyleSheet("color: #555;"); return l

    def apply_styles(self):
        self.setStyleSheet("""
            QMainWindow { background-color: #1e1e1e; color: #fff; }
            QPushButton { padding: 8px; border-radius: 4px; background: #424242; color: white; border: 1px solid #555; }
            QPushButton:hover { background: #505050; }
            QScrollArea { border: none; background: transparent; }
            QWidget { background: transparent; }
            QComboBox { padding: 5px; background: #333; color: white; border: 1px solid #555; }
        """)

    def closeEvent(self, event):
        if self.thread: self.thread.stop()
        event.accept()
    
    # --- [M·ªöI] H√ÄM HI·ªÜN MENU X√ìA ---
    def show_context_menu(self, pos, student_id):
        menu = QMenu(self)
        delete_action = menu.addAction(f"‚ùå X√≥a v·ªã tr√≠ HS-{student_id}")
        
        # L·∫•y widget g·ª≠i t√≠n hi·ªáu ƒë·ªÉ hi·ªÉn th·ªã menu ƒë√∫ng ch·ªó
        sender_widget = self.student_widgets.get(student_id)
        if sender_widget:
            # Chuy·ªÉn ƒë·ªïi t·ªça ƒë·ªô ƒë·ªÉ menu hi·ªán ngay t·∫°i con chu·ªôt
            global_pos = sender_widget.mapToGlobal(pos)
            action = menu.exec(global_pos)
            
            if action == delete_action:
                self.delete_zone(student_id)

    # --- [M·ªöI] H√ÄM X·ª¨ L√ù LOGIC X√ìA ---
    def delete_zone(self, student_id):
        if not self.thread: return
        
        reply = QMessageBox.question(self, 'X√°c nh·∫≠n', 
                                   f"B·∫°n c√≥ ch·∫Øc mu·ªën x√≥a v√πng theo d√µi HS-{student_id}?",
                                   QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No)
        
        if reply == QMessageBox.StandardButton.Yes:
            # 1. X√≥a kh·ªèi danh s√°ch v√πng trong VideoThread
            # L·ªçc l·∫°i danh s√°ch, gi·ªØ l·∫°i nh·ªØng v√πng KH√îNG ph·∫£i l√† ID c·∫ßn x√≥a
            self.thread.zones = [z for z in self.thread.zones if str(z['id']) != str(student_id)]
            
            # 2. X√≥a widget tr√™n giao di·ªán
            if student_id in self.student_widgets:
                self.student_widgets[student_id].setParent(None)
                del self.student_widgets[student_id]
            
            # 3. S·∫Øp x·∫øp l·∫°i giao di·ªán Grid
            # (H√†m update_student_panel s·∫Ω t·ª± lo vi·ªác v·∫Ω l·∫°i c√°c √¥ c√≤n l·∫°i)
            print(f"ƒê√£ x√≥a v√πng HS-{student_id}")

def resource_path(relative_path):
    try:
        base_path = sys._MEIPASS  # PyInstaller (onefile)
    except Exception:
        base_path = os.path.abspath(".")  # onedir / ch·∫°y .py
    return os.path.join(base_path, relative_path)


if __name__ == "__main__":
    app = QApplication(sys.argv)

    # üî• SET ICON TASKBAR
    app.setWindowIcon(QIcon(resource_path("AI Smart Monitor.ico")))

    window = CameraMonitorUI()
    window.show()
    sys.exit(app.exec())
